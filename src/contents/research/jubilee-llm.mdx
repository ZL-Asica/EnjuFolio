---
title: 'Coach-Style LLM Assistant for Safe Lab Automation on the Jubilee Platform'
authors:
  - Zhuoran Liu
  - Danli Luo
  - Karan Ahuja
  - Nadya Peek
advisors:
  - Dr. Nadya Peek (University of Washington)
date: 2025-05
venue: 'CHI 2027'
status: 'In preparation'
role: 'Co-lead author'
abstract: >
  I am developing a coach-style LLM assistant that turns wet-lab researchers’ plain-English goals into safe Jubilee automation code. By bridging verified APIs with documentation-grounded logic, the system runs dry-run simulations and safety checks before execution, supporting a mixed-initiative workflow that balances automation with human oversight.
keywords:
  - Lab automation
  - Large language models
  - Mixed-initiative interfaces
  - Documentation-grounded code generation
  - Safety and reliability
  - Human–AI collaboration
---

## Overview

Under the **joint supervision of Dr. Nadya Peek (UW)**, I am exploring how an LLM can coach, rather than replace, non-programmer scientists using Jubilee, an open-source multi-tool lab automation platform. Many users understand their biology deeply but struggle with the Science Jubilee Python library; my approach frames this not as a simple “natural language to code” problem, but as a **mixed-initiative coaching task**. The assistant translates plain-English goals into machine steps while preserving user control, ingesting device manuals and calibration notes to compile goals into code that only touches verified APIs.

Crucially, the system automatically inserts **dry-run simulations and safety checks** before any real motion occurs. I focused heavily on **iterating on failure cases**: whenever simulations revealed unsafe trajectories or ambiguous device states, I treated them as design opportunities—tightening constraint representations and adjusting how the assistant explains trade-offs. The interface logs every assumption for audit and exposes generated code to invite inspection rather than hiding it. Following approval from the UW IRB, and building on pilot deployments that reduced invalid steps, I am now designing a user study to evaluate task success and safety violations, aiming to establish a recipe for **dependable, documentation-grounded automation tools** in scientific research.
